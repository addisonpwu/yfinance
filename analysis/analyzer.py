import yfinance as yf
import pandas as pd
import pkgutil
import importlib
import inspect
import os
import json
import subprocess
import re
import time
from datetime import datetime, timedelta
from strategies.base_strategy import BaseStrategy
from data_loader import us_loader, hk_loader
from ai_analyzer import analyze_stock_with_ai

def parse_kronos_prediction(prediction_text: str) -> tuple[float, float]:
    """
    è§£æ Kronos é¢„æµ‹è¾“å‡ºï¼Œæå–ä¸Šå‡å’Œä¸‹è·Œæœºç‡

    Args:
        prediction_text: Kronos é¢„æµ‹è„šæœ¬çš„è¾“å‡ºæ–‡æœ¬

    Returns:
        (ä¸Šå‡æœºç‡, ä¸‹è·Œæœºç‡) çš„å…ƒç»„ï¼Œå¦‚æœè§£æå¤±è´¥è¿”å› (0, 0)
    """
    try:
        # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–æœºç‡
        rise_match = re.search(r'åƒ¹æ ¼ä¸Šå‡æ©Ÿç‡:\s*([\d.]+)%', prediction_text)
        fall_match = re.search(r'åƒ¹æ ¼ä¸‹è·Œæ©Ÿç‡:\s*([\d.]+)%', prediction_text)

        if rise_match and fall_match:
            rise_prob = float(rise_match.group(1))
            fall_prob = float(fall_match.group(1))
            return rise_prob, fall_prob
        else:
            return 0.0, 0.0
    except Exception as e:
        print(f"è§£æ Kronos é¢„æµ‹æœºç‡æ—¶å‡ºé”™: {e}")
        return 0.0, 0.0

def get_strategies():
    """
    å‹•æ…‹å¾ strategies æ¨¡çµ„åŠ è¼‰æ‰€æœ‰ç­–ç•¥é¡åˆ¥çš„å¯¦ä¾‹ã€‚
    """
    strategies = []
    import strategies as strategies_module
    strategy_path = strategies_module.__path__

    for _, name, _ in pkgutil.iter_modules(strategy_path):
        if name != 'base_strategy':
            module = importlib.import_module(f"strategies.{name}")
            for item_name, item in inspect.getmembers(module, inspect.isclass):
                if issubclass(item, BaseStrategy) and item is not BaseStrategy:
                    strategies.append(item())
    return strategies

def _read_csv_with_auto_index(csv_file: str) -> pd.DataFrame:
    """
    è¯»å– CSV æ–‡ä»¶ï¼Œè‡ªåŠ¨æ£€æµ‹å¹¶ä½¿ç”¨æ­£ç¡®çš„ç´¢å¼•åˆ—åï¼ˆDate æˆ– Datetimeï¼‰

    Args:
        csv_file: CSV æ–‡ä»¶è·¯å¾„

    Returns:
        DataFrame
    """
    # å…ˆè¯»å–ç¬¬ä¸€è¡Œæ¥æ£€æµ‹åˆ—å
    with open(csv_file, 'r') as f:
        first_line = f.readline()
    
    # æ£€æµ‹ç´¢å¼•åˆ—å
    if 'Datetime,' in first_line:
        index_col = 'Datetime'
    else:
        index_col = 'Date'
    
    # ä½¿ç”¨æ­£ç¡®çš„ç´¢å¼•åˆ—åè¯»å–
    return pd.read_csv(csv_file, index_col=index_col, parse_dates=True)

def get_data_with_cache(symbol: str, market: str, fast_mode: bool = False, interval: str = '1d') -> (pd.DataFrame, dict, dict):
    """
    ç²å–è‚¡ç¥¨æ•¸æ“šï¼Œæ ¹æ“šæ¨¡å¼é¸æ“‡å¿«é€ŸåŠ è¼‰æˆ–åŒæ­¥æ›´æ–°ã€‚

    Args:
        symbol: è‚¡ç¥¨ä»£ç¢¼
        market: å¸‚å ´ä»£ç¢¼ ('US' æˆ– 'HK')
        fast_mode: æ˜¯å¦ä½¿ç”¨å¿«é€Ÿæ¨¡å¼
        interval: æ•¸æ“šæ™‚æ®µé¡å‹ ('1d' æ—¥ç·š, '1h' å°æ™‚ç·š, '1m' åˆ†é˜ç·š)
    """
    cache_dir = os.path.join('data_cache', market.upper())
    # ç¡®ä¿ç¼“å­˜ç›®å½•å­˜åœ¨
    os.makedirs(cache_dir, exist_ok=True)
    safe_symbol = symbol.replace(":", "_")
    csv_file = os.path.join(cache_dir, f"{safe_symbol}_{interval}.csv")  # æ·»åŠ  interval åˆ°æ–‡ä»¶å
    json_file = os.path.join(cache_dir, f"{safe_symbol}.json")

    ticker = yf.Ticker(symbol)

    if fast_mode:
        try:
            # print(f" - [å¿«é€Ÿæ¨¡å¼] å¾ç·©å­˜åŠ è¼‰", end='')
            # è‡ªåŠ¨æ£€æµ‹ç´¢å¼•åˆ—åï¼ˆDate æˆ– Datetimeï¼‰
            hist = _read_csv_with_auto_index(csv_file)
            with open(json_file, 'r', encoding='utf-8') as f:
                info = json.load(f)
            news = ticker.news # æ–°èç¸½æ˜¯ç²å–æœ€æ–°çš„
            return hist, info, news
        except FileNotFoundError:
            # print(f" - [å¿«é€Ÿæ¨¡å¼] ç·©å­˜æ–‡ä»¶æœªæ‰¾åˆ°ï¼Œåˆ‡æ›åˆ°æ­£å¸¸æ¨¡å¼ä¸‹è¼‰", end='')
            return get_data_with_cache(symbol, market, fast_mode=False, interval=interval)

    # --- æ­£å¸¸åŒæ­¥æ¨¡å¼ ---
    today = datetime.now().date()
    hist, info, news = pd.DataFrame(), {}, []

    try:
        info = ticker.info
        news = ticker.news
    except Exception as e:
        print(f" - ç„¡æ³•ç²å– {symbol} çš„ info/news: {e}", end='')

    if os.path.exists(csv_file):
        # è‡ªåŠ¨æ£€æµ‹ç´¢å¼•åˆ—åï¼ˆDate æˆ– Datetimeï¼‰
        hist = _read_csv_with_auto_index(csv_file)
        last_cached_date = hist.index.max().date()

        if last_cached_date >= today:
            print(f" - å¾ç·©å­˜åŠ è¼‰ {len(hist)} æ¢æ•¸æ“š", end='')
        else:
            start_date = last_cached_date + timedelta(days=1)
            print(f" - ç·©å­˜æ•¸æ“šéèˆŠï¼Œæ­£åœ¨å¾ {start_date.strftime('%Y-%m-%d')} ä¸‹è¼‰å¢é‡æ•¸æ“š...", end='')
            new_hist = ticker.history(start=start_date.strftime('%Y-%m-%d'), interval=interval, auto_adjust=True)
            if not new_hist.empty:
                hist = pd.concat([hist, new_hist])
                print(f"ä¸‹è¼‰äº† {len(new_hist)} æ¢æ–°æ•¸æ“š", end='')
            else:
                print("æ²’æœ‰æ–°çš„æ•¸æ“šå¯ä¸‹è¼‰", end='')
    else:
        print(" - ç·©å­˜ä¸å­˜åœ¨ï¼Œæ­£åœ¨ä¸‹è¼‰å…¨éƒ¨æ­·å²æ•¸æ“š...", end='')
        # æ ¹æ“š interval è¨­ç½®ä¸åŒçš„ period
        if interval == '1m':
            period = '7d'  # åˆ†é˜ç·šåªä¸‹è¼‰æœ€è¿‘7å¤©
        elif interval == '1h':
            period = '730d'  # å°æ™‚ç·šä¸‹è¼‰æœ€è¿‘2å¹´
        else:
            period = 'max'  # æ—¥ç·šä¸‹è¼‰å…¨éƒ¨æ­·å²
        hist = ticker.history(period=period, interval=interval, auto_adjust=True)
        print(f"ä¸‹è¼‰äº† {len(hist)} æ¢æ•¸æ“š", end='')

    # ç„¡è«–æ˜¯æ›´æ–°é‚„æ˜¯æ–°å¢ï¼Œéƒ½ç”¨æœ€æ–°çš„æ•¸æ“šè¦†è“‹ç·©å­˜
    if not hist.empty:
        float_shares = info.get('floatShares', None)
        hist['FloatShares'] = float_shares
        hist.to_csv(csv_file)

    if info:
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(info, f, ensure_ascii=False, indent=4)

    return hist, info, news

def run_analysis(market: str, force_fast_mode: bool = False, use_kronos: bool = True, symbol_filter: str = None, interval: str = '1d'):
    """
    å°æŒ‡å®šå¸‚å ´åŸ·è¡Œæ‰€æœ‰é¸è‚¡ç­–ç•¥åˆ†æ

    Args:
        market: å¸‚å ´ä»£ç¢¼ ('US' æˆ– 'HK')
        force_fast_mode: æ˜¯å¦å¼·åˆ¶è·³éç·©å­˜æ›´æ–°ï¼Œç›´æ¥ä½¿ç”¨å¿«é€Ÿæ¨¡å¼
        use_kronos: æ˜¯å¦ä½¿ç”¨ Kronos é æ¸¬ï¼ˆåƒ…é©ç”¨æ–¼æ¸¯è‚¡ï¼‰
        symbol_filter: æŒ‡å®šåˆ†æå–®ä¸€è‚¡ç¥¨ä»£ç¢¼ï¼ˆä¾‹å¦‚ï¼š0017.HKï¼‰
        interval: æ•¸æ“šæ™‚æ®µé¡å‹ ('1d' æ—¥ç·š, '1h' å°æ™‚ç·š, '1m' åˆ†é˜ç·š)
    """
    # --- å…¨å±€ç·©å­˜ç‰ˆæœ¬æª¢æŸ¥ ---
    version_file = os.path.join('data_cache', market.upper(), 'version.txt')
    today_str = datetime.now().date().isoformat()
    is_sync_needed = True

    if force_fast_mode:
        is_sync_needed = False
        print(f"--- å¼·åˆ¶å¿«é€Ÿæ¨¡å¼ï¼šè·³éç·©å­˜æ›´æ–°æª¢æŸ¥ ---")
    else:
        try:
            with open(version_file, 'r') as f:
                last_sync_date = f.read().strip()
            if last_sync_date == today_str:
                is_sync_needed = False
                print(f"--- æ•¸æ“šç·©å­˜å·²æ˜¯æœ€æ–° ({today_str})ï¼Œå°‡ä»¥å¿«é€Ÿæ¨¡å¼é‹è¡Œ ---")
            else:
                print(f"--- æ•¸æ“šç·©å­˜ä¸æ˜¯æœ€æ–° (ç‰ˆæœ¬: {last_sync_date})ï¼Œå°‡åŸ·è¡Œå¢é‡åŒæ­¥ ---")
        except FileNotFoundError:
            print("--- æœªæ‰¾åˆ°ç·©å­˜ç‰ˆæœ¬æ–‡ä»¶ï¼Œå°‡åŸ·è¡Œé¦–æ¬¡åŒæ­¥ ---")

    # --- ç²å–è‚¡ç¥¨åˆ—è¡¨ ---
    # å…ˆå®šç¾© market_ticker
    if market.upper() == 'US':
        market_ticker = '^GSPC'
    elif market.upper() == 'HK':
        market_ticker = '^HSI'
    else:
        print(f"éŒ¯èª¤: ä¸æ”¯æ´çš„å¸‚å ´ '{market}'ã€‚è«‹ä½¿ç”¨ 'US' æˆ– 'HK'ã€‚")
        return []

    if symbol_filter:
        # å¦‚æœæŒ‡å®šäº†å–®ä¸€è‚¡ç¥¨ï¼Œç›´æ¥ä½¿ç”¨è©²è‚¡ç¥¨
        tickers = [symbol_filter]
        print(f"--- ä½¿ç”¨æŒ‡å®šè‚¡ç¥¨: {symbol_filter} ---")
    else:
        # å¦å‰‡ç²å–æ•´å€‹å¸‚å ´çš„è‚¡ç¥¨åˆ—è¡¨
        if market.upper() == 'US':
            tickers = us_loader.get_us_tickers()
        elif market.upper() == 'HK':
            tickers = hk_loader.get_hk_tickers()

    is_market_healthy = False
    market_latest_return = 0.0
    try:
        market_hist = yf.Ticker(market_ticker).history(period='1y', auto_adjust=True)
        if not market_hist.empty and len(market_hist) >= 200:
            market_latest_return = market_hist['Close'].pct_change().iloc[-1] * 100
            market_hist['MA200'] = market_hist['Close'].rolling(window=200).mean()
            latest_market_data = market_hist.iloc[-1]
            is_market_healthy = latest_market_data['Close'] > latest_market_data['MA200']
            market_status_str = "å¤šé ­" if is_market_healthy else "ç©ºé ­"
            print(f"å·²æˆåŠŸç²å–å¤§ç›¤({market_ticker})æ•¸æ“šã€‚ä»Šæ—¥æ¼²è·Œ: {market_latest_return:.2f}%ã€‚å¸‚å ´è¶¨å‹¢: {market_status_str}")
        else:
            print(f"å¤§ç›¤æ­·å²æ•¸æ“šä¸è¶³ä»¥è¨ˆç®—200MA")
    except Exception as e:
        print(f"ç„¡æ³•ä¸‹è¼‰æˆ–åˆ†æå¤§ç›¤æ•¸æ“š ({market_ticker})ï¼Œç­–ç•¥ä¸­çš„å¤§ç›¤æ¿¾ç¶²å°‡ä¸æœƒå•Ÿç”¨ã€‚éŒ¯èª¤: {e}")

    strategies_to_run = get_strategies()
    if not strategies_to_run:
        print("è­¦å‘Š: åœ¨ 'strategies' æ–‡ä»¶å¤¾ä¸­æ²’æœ‰æ‰¾åˆ°ä»»ä½•ç­–ç•¥ã€‚")
        return []
    print(f"å·²åŠ è¼‰ {len(strategies_to_run)} å€‹ç­–ç•¥: {[s.name for s in strategies_to_run]}")

    # --- é€å€‹è‚¡ç¥¨é€²è¡Œåˆ†æå’Œé æ¸¬ ---
    print(f"\n--- é–‹å§‹é€å€‹è‚¡ç¥¨é€²è¡Œåˆ†æå’Œé æ¸¬ ---")
    qualified_stocks = []
    total_stocks = len(tickers)
    analyzed_count = 0
    
    for i, symbol in enumerate(tickers):
        progress = (i + 1) / total_stocks
        print(f"\råˆ†æé€²åº¦: [{int(progress * 20) * '#'}{int((1 - progress) * 20) * '-'}] {i+1}/{total_stocks} - æ­£åœ¨åˆ†æ {symbol}...", end='')

        try:
            # æ·»åŠ è¯·æ±‚å»¶è¿Ÿï¼Œé¿å…è§¦å‘ yfinance API é€Ÿç‡é™åˆ¶
            time.sleep(1.0)
            
            # ç²å–è‚¡ç¥¨æ•¸æ“šï¼ˆæœƒè‡ªå‹•è™•ç†ç·©å­˜ï¼‰
            hist, info, news = get_data_with_cache(symbol, market, fast_mode=not is_sync_needed, interval=interval)
            
            if hist.empty or len(hist) < 2 or not info:
                continue
            
            analyzed_count += 1
            
            # åŸ·è¡Œæ‰€æœ‰ç­–ç•¥
            passed_strategies = []
            for strategy in strategies_to_run:
                if strategy.run(hist.copy(), info=info, market_return=market_latest_return, is_market_healthy=is_market_healthy):
                    passed_strategies.append(strategy.name)
            
            if passed_strategies:
                # æ­¥éª¤ 1: AI åˆ†æï¼ˆåœ¨ Kronos é¢„æµ‹ä¹‹å‰ï¼‰
                ai_analysis = None
                try:
                    ai_analysis = analyze_stock_with_ai({
                        'symbol': symbol,
                        'strategies': passed_strategies,
                        'info': info,
                        'market': market
                    }, hist, interval)
                except Exception as ai_e:
                    print(f" - AI åˆ†æå‡ºé”™: {ai_e}", end='')

                # æ­¥éª¤ 2: è°ƒç”¨ Kronos é¢„æµ‹ï¼ˆä»…æ¸¯è‚¡ä¸”å¯ç”¨ Kronosï¼‰
                kronos_prediction = "N/A"
                rise_prob = 0.0
                fall_prob = 0.0
                KRONOS_SCRIPT_PATH = "/Users/addison/Develop/yfinace/Kronos/scripts/prediction_hk.py"

                if market.upper() == 'HK' and use_kronos:
                    try:
                        command = ["python3", KRONOS_SCRIPT_PATH, symbol]
                        process = subprocess.run(
                            command,
                            capture_output=True,
                            text=True,
                            check=True,
                            timeout=300
                        )
                        kronos_prediction = process.stdout.strip()
                        # è§£æä¸Šå‡/ä¸‹è·Œæœºç‡
                        rise_prob, fall_prob = parse_kronos_prediction(kronos_prediction)
                    except subprocess.CalledProcessError as e:
                        error_output = e.stderr.strip()
                        kronos_prediction = f"é æ¸¬å¤±æ•—: {error_output}"
                    except subprocess.TimeoutExpired:
                        kronos_prediction = "é æ¸¬è¶…æ™‚"
                    except Exception as pred_e:
                        kronos_prediction = f"èª¿ç”¨å¤–éƒ¨è…³æœ¬æ™‚å‡ºéŒ¯: {pred_e}"

                # æ­¥éª¤ 3: ä»…å½“ä¸Šå‡æœºç‡ > ä¸‹è·Œæœºç‡æ—¶æ‰åŠ å…¥ qualified_stocksï¼ˆå¦‚æœå¯ç”¨äº† Kronosï¼‰
                # å¦‚æœæœªå¯ç”¨ Kronosï¼Œåˆ™ç›´æ¥åŠ å…¥ qualified_stocks
                if not use_kronos or rise_prob > fall_prob:
                    exchange = info.get('exchange', 'UNKNOWN')
                    qualified_stocks.append({
                        'symbol': symbol,
                        'exchange': exchange,
                        'strategies': passed_strategies,
                        'info': info,
                        'news': news,
                        'kronos_prediction': kronos_prediction,
                        'rise_prob': rise_prob,
                        'fall_prob': fall_prob,
                        'ai_analysis': ai_analysis
                    })
                    if use_kronos:
                        print(f"\r{' ' * 80}\râœ… {symbol} ç¬¦åˆç­–ç•¥: {passed_strategies}, ä¸Šå‡æ©Ÿç‡: {rise_prob:.2f}% vs ä¸‹è·Œæ©Ÿç‡: {fall_prob:.2f}%")
                    else:
                        print(f"\r{' ' * 80}\râœ… {symbol} ç¬¦åˆç­–ç•¥: {passed_strategies}")
                    # è¾“å‡º AI åˆ†æç»“æœåˆ° console
                    if ai_analysis:
                        print(f"   ğŸ¤– AI åˆ†æ: {ai_analysis['summary']}")
                        print(f"   ğŸ¤– AI æ¨¡å‹: {ai_analysis['model_used']}")
                    else:
                        print(f"   ğŸ¤– AI åˆ†æ: æœªèƒ½å®Œæˆ")
                else:
                    print(f"\r{' ' * 80}\râ­ï¸  {symbol} ç¬¦åˆç­–ç•¥ä½†ä¸Šå‡æ©Ÿç‡({rise_prob:.2f}%) â‰¤ ä¸‹è·Œæ©Ÿç‡({fall_prob:.2f}%)ï¼Œå·²è·³é")

        except Exception as e:
            print(f"\r{' ' * 80}\râŒ åˆ†æ {symbol} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            pass
    
    # --- æ›´æ–°ç·©å­˜ç‰ˆæœ¬æ–‡ä»¶ ---
    if is_sync_needed:
        print(f"\n--- æ›´æ–°ç·©å­˜ç‰ˆæœ¬è‡³ {today_str} ---")
        with open(version_file, 'w') as f:
            f.write(today_str)
    
    print(f"\n--- åˆ†æå®Œæˆï¼æˆåŠŸåˆ†æ {analyzed_count}/{total_stocks} æ”¯è‚¡ç¥¨ï¼Œæ‰¾åˆ° {len(qualified_stocks)} æ”¯ç¬¦åˆæ¢ä»¶çš„è‚¡ç¥¨ ---")
    return qualified_stocks